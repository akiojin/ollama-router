# 機能仕様書: コーディネーター主導のモデル自動配布機能

**機能ID**: `SPEC-8ae67d67`
**作成日**: 2025-11-12
**ステータス**: 下書き
**入力**: ユーザー説明: "コーディネーター主導のモデル自動配布機能"

## ユーザーシナリオ＆テスト *(必須)*

### ユーザーストーリー1 - エージェント登録時の自動モデル配布 (優先度: P1)

管理者として、新しいエージェントを登録したときに、そのエージェントのGPU能力に応じた適切なサイズのAIモデルが自動的にダウンロードされ、すぐに推論タスクを実行できる状態になることを期待します。

**この優先度の理由**: これは最も基本的かつ重要な機能です。エージェントが登録された直後から使用可能な状態になることで、運用開始までの時間を大幅に短縮し、手動設定の手間を排除できます。

**独立テスト**: エージェント登録APIを呼び出し、登録完了後にモデルダウンロードが自動的に開始されることを確認することで、この機能を完全にテストできます。

**受け入れシナリオ**:

1. **前提** 16GB以上のGPUメモリを持つ新しいエージェントがシステムに存在、**実行** エージェント登録APIを呼び出す、**結果** 登録完了後、gpt-oss:20bモデルのダウンロードが自動的に開始され、完了する
2. **前提** 8GB以上16GB未満のGPUメモリを持つエージェントが登録される、**実行** エージェント登録APIを呼び出す、**結果** gpt-oss:7bモデルが自動的にダウンロードされる
3. **前提** 4.5GB以上8GB未満のGPUメモリを持つエージェントが登録される、**実行** エージェント登録APIを呼び出す、**結果** gpt-oss:3bモデルが自動的にダウンロードされる
4. **前提** 4.5GB未満のGPUメモリを持つエージェントが登録される、**実行** エージェント登録APIを呼び出す、**結果** gpt-oss:1bモデルが自動的にダウンロードされる
5. **前提** モデルダウンロード中のエージェント、**実行** ダッシュボードでエージェント詳細を表示、**結果** ダウンロード進捗（パーセンテージ）がリアルタイムで表示される

---

### ユーザーストーリー2 - ダッシュボードからの手動モデル配布 (優先度: P2)

管理者として、ダッシュボードから特定のエージェントまたは全エージェントに対して、任意のモデルをダウンロードするように指示できることを期待します。これにより、新しいモデルのテストや、特定のタスクに最適化されたモデルの配布が可能になります。

**この優先度の理由**: 自動配布だけでは不十分なケースに対応します。新しいモデルのリリース時や、特定のユースケースに特化したモデルを配布する必要がある場合に、管理者が柔軟に制御できる必要があります。

**独立テスト**: ダッシュボードUIから「モデルをダウンロード」ボタンをクリックし、指定したエージェントでモデルダウンロードが開始されることを確認することで、この機能をテストできます。

**受け入れシナリオ**:

1. **前提** ダッシュボードでエージェント一覧を表示中、**実行** 特定のエージェントを選択し、モデル名を入力して「ダウンロード」ボタンをクリック、**結果** 選択したエージェントでモデルダウンロードが開始され、進捗が表示される
2. **前提** ダッシュボードでモデル配布画面を表示中、**実行** 「全エージェントに配布」オプションを選択してモデル名を指定、**結果** すべてのオンラインエージェントで同時にモデルダウンロードが開始される
3. **前提** モデルダウンロード中のエージェント、**実行** ダウンロード進捗を確認、**結果** 各エージェントのダウンロード状況（進行中/完了/失敗）が一覧表示される
4. **前提** エージェントがオフライン状態、**実行** そのエージェントにモデルダウンロードを指示、**結果** エラーメッセージが表示され、「エージェントがオンラインになったら再試行」オプションが提示される

---

### ユーザーストーリー3 - モデル情報の可視化 (優先度: P3)

管理者として、どのモデルがダウンロード可能で、各エージェントに現在どのモデルがインストールされているかを一覧で確認できることを期待します。これにより、システム全体のモデル配布状況を把握し、適切な管理判断を行えます。

**この優先度の理由**: 情報可視化は運用効率を向上させますが、実際のモデル配布機能（P1、P2）が動作していればシステムとしては機能します。優先度は低いですが、長期的な運用には不可欠です。

**独立テスト**: ダッシュボードで「モデル管理」画面を開き、ダウンロード可能なモデル一覧と各エージェントのインストール済みモデルが表示されることを確認することで、この機能をテストできます。

**受け入れシナリオ**:

1. **前提** ダッシュボードでモデル管理画面を表示、**実行** 「ダウンロード可能なモデル」タブを選択、**結果** Ollama公式ライブラリから取得したモデル一覧（名前、サイズ、説明）が表示される
2. **前提** ダッシュボードでエージェント詳細画面を表示、**実行** 「インストール済みモデル」セクションを確認、**結果** そのエージェントにインストールされているモデルの一覧（名前、サイズ、インストール日時）が表示される
3. **前提** 複数のエージェントが異なるモデルをインストール済み、**実行** モデル管理画面でエージェント別のマトリクス表示を選択、**結果** どのエージェントにどのモデルがインストールされているかが一目で分かる表形式で表示される

---

### エッジケース

- ダウンロード中にエージェントがオフラインになった場合、どうなるか？
  - エージェント側でダウンロードが中断され、次回オンライン時に再開できる
- 既にインストール済みのモデルを再度ダウンロードしようとした場合、どうなるか？
  - システムは警告メッセージを表示し、「スキップ」または「再ダウンロード」の選択肢を提示する
- エージェントのディスク容量が不足している場合、どうなるか？
  - ダウンロード前にディスク容量チェックを行い、不足している場合はエラーメッセージを表示する
- Ollama公式ライブラリAPIがアクセス不能な場合、どうなるか？
  - 既存エージェントの `ollama list` からモデル一覧を取得し、縮退運転モードで動作する
- 同時に複数のモデルダウンロードが要求された場合、どうなるか？
  - エージェント側でキューイングし、順次ダウンロードを実行する（同時ダウンロード数は設定可能）

## 要件 *(必須)*

### 機能要件

- **FR-001**: システムはエージェント登録時に、そのエージェントのGPUメモリサイズに基づいて適切なモデルサイズを自動選択する必要がある
- **FR-002**: システムは管理者がダッシュボードから特定のエージェントに任意のモデルをダウンロードするよう指示できる必要がある
- **FR-003**: システムは管理者が全エージェントに一括でモデルを配布できる必要がある
- **FR-004**: システムはモデルダウンロードの進捗（パーセンテージ、ダウンロード速度、残り時間）をリアルタイムで表示する必要がある
- **FR-005**: システムはOllama公式ライブラリからダウンロード可能なモデル一覧を取得して表示する必要がある
- **FR-006**: システムは各エージェントのインストール済みモデル一覧を取得して表示する必要がある
- **FR-007**: システムはモデルダウンロード失敗時に詳細なエラーメッセージを表示する必要がある
- **FR-008**: システムはエージェントがオフライン時のダウンロード要求を適切に処理し、エラーメッセージを表示する必要がある
- **FR-009**: エージェント登録完了後、コーディネーターが対応している全モデルが当該エージェントで自動ダウンロード・常駐状態になること（完了判定はコーディネーターで確認可能）
- **FR-009**: システムは既存のエージェント自律ダウンロード機能（OLLAMA_DEFAULT_MODEL）と独立して動作する必要がある
- **FR-010**: システムはダウンロード前にエージェントのディスク容量を確認し、不足している場合は警告を表示する必要がある

### 主要エンティティ

- **モデル情報**: Ollamaモデルの名前、サイズ、説明、必要メモリを表す
- **ダウンロードタスク**: エージェントID、モデル名、開始時刻、進捗状況、ステータス（進行中/完了/失敗）を含む
- **エージェントモデル状態**: 各エージェントにインストールされているモデルの一覧と、それぞれのインストール日時、サイズを保持する

---

## スコープ外 *(オプション)*

以下の機能は本仕様のスコープ外とし、将来のバージョンで対応予定:

- モデルの自動更新機能（新しいバージョンがリリースされたときの自動アップグレード）
- モデルのアンインストール機能（ディスク容量削減のための削除）
- カスタムモデルのアップロード・配布（独自にファインチューニングしたモデルの配布）
- モデルダウンロードのスケジューリング（特定時刻に実行）
- ダウンロード帯域幅の制限設定

---

## 技術制約 *(該当する場合)*

- Ollama公式ライブラリAPIへのアクセスにはインターネット接続が必要
- モデルダウンロードはエージェント側のディスク容量に依存する
- 進捗情報のリアルタイム更新には、エージェントとコーディネーター間の安定したネットワーク接続が必要

---

## 前提条件 *(該当する場合)*

この機能は以下を前提とします:

- エージェントがGPU情報を含めて正常に登録されている（SPEC-5cd7b614の要件）
- エージェント側にOllamaがインストールされている、または自動インストール機能が有効である
- コーディネーターとエージェント間の通信が正常に機能している

---

## 依存関係 *(該当する場合)*

この機能は以下に依存します:

- エージェント自己登録システム（SPEC-94621a1f）
- GPU必須エージェント登録要件（SPEC-5cd7b614）
- ヘルスチェックシステム（SPEC-443acc8c）- エージェントのオンライン/オフライン状態の把握に必要
- 管理ダッシュボード（SPEC-712c20cf）- UI操作のベースとして必要

---

## 対応モデル（固定要件）

コーディネーターが公式にサポートするモデルは次の4件に限定する。

- gpt-oss:20b
- gpt-oss:120b
- gpt-oss-safeguard:20b
- qwen3-coder:30b

**制約**
- 上記以外のモデルは「対応モデル」として扱わない。UIと /v1/models は常にこの固定リストのみ返す。
- エージェント登録完了後、対応モデル4件をまとめて自動ダウンロードし常駐させる（手動配布は不要）。
- 旧GPU帯域別モデル（gpt-oss:7b/3b/1b 等）の自動選択は廃止する。

---

## アーキテクチャ要件（通信経路）

- コーディネーターはエージェントの「OpenAI互換API（単一ポート、標準は Ollama ポート+1）」のみと通信する。  
  - 登録ヘルスチェック、モデル自動配布指示、推論プロキシ（chat/completions/embeddings）はすべてエージェントAPI経由。  
  - コーディネーターがエージェント内部の Ollama を直接叩かないこと。  
- エージェントは受けた OpenAI互換リクエストを内部の Ollama にルーティングし、必要なモデルを ensure/pull してから実行する。  
- 複数 Ollama 実体を持つ場合の振り分けはエージェント側の責務とし、コーディネーターは単一 API エンドポイントだけを認識すればよい。  
- `/v1/models` 応答はコーディネーターが定義する対応モデル固定リストを返す（エージェント側で揃える）。

### モデル起動完了までの受付制御
- 対応モデル4件がすべて起動・常駐完了するまではエージェントは `initializing` 状態とし、ロードバランサの選択対象外とする。  
- コーディネーターからの推論リクエストは、全エージェントが `initializing` の場合は 503（モデル起動中）を返し、後続で待機キューへリクエストを積む。  
- ハートビートで `initializing` フラグと `ready_models`（起動済み/総数）を送信する。  
- エージェントAPI `/v1/models` でも進捗情報を返せること（任意だが推奨）。

---

## 成功基準 *(必須)*

以下の成功基準を満たす必要があります:

1. エージェント登録から5分以内に、適切なサイズのモデルダウンロードが完了し、推論タスクを実行できる状態になる
2. 管理者がダッシュボードから3クリック以内でモデル配布操作を完了できる
3. モデルダウンロードの進捗情報が5秒以内に更新される
4. ダウンロード可能なモデル一覧の取得が10秒以内に完了する
5. 全エージェントへの一括配布操作が30秒以内に開始される（各エージェントでのダウンロード開始まで）
6. モデルダウンロード成功率が95%以上である（ネットワークエラー等を除く）
7. エージェントのインストール済みモデル一覧の取得が3秒以内に完了する
8. システムは同時に10個のモデルダウンロードタスクを処理できる
9. エージェント登録完了後、対応モデル4件（gpt-oss:120b/20b、gpt-oss-safeguard:20b、qwen3-coder:30b）が当該エージェントで自動ダウンロード・常駐状態になること（ダッシュボードまたは API で確認可能であること）

---

## ⚡ クイックガイドライン

- ✅ ユーザーが「何を」必要とし「なぜ」必要なのかに焦点を当てる
- ❌ 「どのように」実装するかを避ける (技術スタック、API、コード構造なし)
- 👥 ビジネス関係者向けに記述 (開発者向けではない)
